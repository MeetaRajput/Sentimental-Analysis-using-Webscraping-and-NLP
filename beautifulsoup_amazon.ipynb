{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41MaYXXf9oZQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_reviews(url):\n",
        "    # Send a GET request to the specified URL\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Create a BeautifulSoup object to parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find the elements containing the reviews\n",
        "    review_elements = soup.find_all('div', class_='review')\n",
        "\n",
        "    # Extract the review text from each element\n",
        "    reviews = []\n",
        "    for review in review_elements:\n",
        "        review_text = review.get_text(strip=True)\n",
        "        reviews.append(review_text)\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Specify the URL of the website you want to scrape reviews from\n",
        "url = 'https://www.amazon.in/Apple-iPhone-13-128GB-Starlight/product-reviews/B09G9D8KRQ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
        "\n",
        "# Call the function to scrape the reviews\n",
        "scraped_reviews = scrape_reviews(url)\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = 'reviews_output.tsv'\n",
        "\n",
        "# Write the reviews to a TSV file\n",
        "with open(output_file, 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file, delimiter='\\t')\n",
        "    writer.writerow(['Review'])\n",
        "    for review in scraped_reviews:\n",
        "        writer.writerow([review])\n",
        "\n",
        "print(f\"Reviews scraped successfully and saved to {output_file}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ETSFNG4Bhhq",
        "outputId": "83799e18-5181-431f-e54e-05974c397e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews scraped successfully and saved to reviews_output.tsv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_reviews(url):\n",
        "    # Send a GET request to the specified URL\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Create a BeautifulSoup object to parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find the elements containing the reviews\n",
        "    review_elements = soup.find_all('div', class_='review')\n",
        "\n",
        "    # Extract the review text from each element\n",
        "    reviews = []\n",
        "    for review in review_elements:\n",
        "        review_text = review.get_text(strip=True)\n",
        "        reviews.append(review_text)\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Specify the URL of the website you want to scrape reviews from\n",
        "url = 'https://www.amazon.in/Apple-iPhone-13-128GB-Starlight/product-reviews/B09G9D8KRQ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'\n",
        "\n",
        "# Call the function to scrape the reviews\n",
        "scraped_reviews = scrape_reviews(url)\n",
        "\n",
        "# Create a DataFrame from the scraped reviews\n",
        "df = pd.DataFrame({'Review': scraped_reviews})\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = 'reviews_output.xlsx'\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Reviews scraped successfully and saved to {output_file}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b7xWZ9oCBa9",
        "outputId": "67305bbe-7d36-4fbc-bd7d-8b4faf1139c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews scraped successfully and saved to reviews_output.xlsx.\n"
          ]
        }
      ]
    }
  ]
}